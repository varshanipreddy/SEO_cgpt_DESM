{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8cH2rRlfU7i"
   },
   "source": [
    "#### CSCE 670 :: Information Storage & Retrieval :: Texas A&M University :: Spring 2023\n",
    "\n",
    "\n",
    "# Homework 3: Fun Homework\n",
    "\n",
    "### 100 points [11% of your final grade]\n",
    "\n",
    "### Due: April 16 (Sunday) by 11:59pm\n",
    "\n",
    "*Goals of this homework:* The objective of this homework is to do something fun (really!). We'll look at search with embeddings, how to be an SEO pro, and play around with ChatGPT. \n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw3.ipynb`. For example, my homework submission would be something like `555001234_hw3.ipynb`. Submit this notebook via eCampus (look for the homework 3 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the 5 total allotted to you).  **However, we will do our first check for Part 1 on the due date April 16 (see below for details).**\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Slack, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwWXS99SzrRp"
   },
   "source": [
    "# Part 1. Search Engine Optimization (20 points)\n",
    "\n",
    "In this part, your goal is to put on your \"[search engine optimization](https://en.wikipedia.org/wiki/Search_engine_optimization)\" hat. Your job is to create a webpage that scores highest for the query **wpaskjbdn zqnakjsnde**. As of today (**March 23**) there are no hits for this query on Google. Based on our discussions of search engine ranking algorithms, you know that several factors may impact a page's rank. Your goal is to use this knowledge to promote your own page to the top of the list.\n",
    "\n",
    "What we're doing here is a form of [SEO contest](https://en.wikipedia.org/wiki/SEO_contest). While you have great latitude in how you approach this problem, you are not allowed to engage in any unethical or illegal behavior. Please read the discussion of \"white hat\" versus \"black hat\" SEO over at [Wikipedia](https://en.wikipedia.org/wiki/Search_engine_optimization).\n",
    "\n",
    "The only requirement is that somewhere in the page (possibly in the html) you must include your name or some other way for us to identify you (e.g., your gmail username).\n",
    "\n",
    "Rules of the game:\n",
    "\n",
    "* Your target page may only be a TAMU student page, a page on your own webserver, a page on a standard platform (e.g., GitHub Pages), or some other primarily user-controlled page.\n",
    "* Your target page MAY NOT be a twitter account, a facebook page, a LinkedIn profile, or similar page.\n",
    "* No wikipedia vandalism.\n",
    "* No comment spamming of blogs or news sites.\n",
    "* If you have concerns/questions/clarifications,please post a message to the slack and we will discuss.\n",
    "\n",
    "On **April 16** (the homework due date), we will examine the rankings on Google only for the query **wpaskjbdn zqnakjsnde**. We will assign points as follows:\n",
    "\n",
    "* 12 points for your explanation of your approach and a link to your target page.\n",
    "* 5 points for creativity in your approach. Basically, did you try some interesting strategy? Did you put some thought into your approach?\n",
    "* 1 points for placing your page in the results returned by Google.\n",
    "* 1 point for placing your page in the top-50 results contributed by students in this class on Google.\n",
    "* 1 point for placing your page in the top-10 results contributed by students in this class on Google.\n",
    "* 1 bonus point, a vigorous announcement in class, and a high-five for having the top result.\n",
    "\n",
    "We encourage you to get started early on this part, so there is time for Google to discover your pages and integrate them into their search results.\n",
    "\n",
    "As an added bonus, we will revisit the rankings at the end of the semester (**sometime in May**) and award bonus points to your final exam. Details to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXyledu3hqV9"
   },
   "source": [
    "## Add Your Link and Discussion Here\n",
    "\n",
    "https://varshanipreddy.github.io/wpaskjbdn-zqnakjsnde/\n",
    "\n",
    "Techniques used:\n",
    "\n",
    "1) Keyword Optimization : added the targeted keyword in the meta tags, content, and heading of the website. This is a on-page optimization technique to help search engines understand the content of the page and match it with relevant user queries.\n",
    "\n",
    "2) Content Optimization: I have made sure the entire content is relevant to the keyword and does not include vague or unrealistic explanations\n",
    "\n",
    "3) Sitemap Generation:  used a crawler to generate a sitemap.xml file for the website. A sitemap helps search engines crawl and index a website more efficiently, making it easier for the pages to show up in search results.\n",
    "\n",
    "4) Google Search Console Submission: submitted sitemap to Google Search Console, a free tool provided by Google that allows you to monitor and optimize your website's presence in search results. By submitting the sitemap, we are informing Google about the structure of the site and helping them understand its content.\n",
    "\n",
    "5) Responsive Design: Optimizing the Website for Different Devices and Screen Sizesn is also important for search engine optimization. My website adapts to all types of screen sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgS43jLbL77U"
   },
   "source": [
    "# Part 2. Adversarial Attacks on ChatGPT (30 points)\n",
    "\n",
    "[Large language models](https://en.wikipedia.org/wiki/Large_language_model) are all the rage these days. You probably have played with [ChatGPT](https://chat.openai.com/) or even Google's [Bard](https://bard.google.com/). Amazing!\n",
    "\n",
    "However, these big models have also been shown to be vulnerable to various types of attacks, including adversarial attacks, bias, and privacy violations. \n",
    "\n",
    "* **Adversarial attacks** involve intentionally modifying input data in a way that can cause the model to produce incorrect or misleading outputs. \n",
    "\n",
    "* **Bias** can arise when the training data used to develop the model is not representative of the real-world population, leading to discriminatory or unfair results. \n",
    "\n",
    "* **Privacy violations** can occur when the model inadvertently exposes sensitive information about individuals or groups. \n",
    "\n",
    "Addressing these vulnerabilities will be crucial in ensuring the safe and responsible deployment of large language models. For this part, we're going to explore these vulnerabilities. You should identify **at least four** examples, with supporting transcripts from your interactions with ChatGPT. \n",
    "\n",
    "Feel free to Google around for inspiration on good vulnerabilities to explore. But try your best to be creative to identify some interesting new cases. We want to see your examples, **plus your analysis of what you found.**\n",
    "\n",
    "As of today (**Mar. 23**), the current version is **ChatGPT Mar 14 Version**. Please submit your examples with the ChatGPT output screenshots and indicate the ChatGPT version.\n",
    "\n",
    "*You should be able to insert images/screenshots of your transcripts here. You may need to Google around for tips on how to insert an image into a colab notebook.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ_3Zv1Dmf0s"
   },
   "source": [
    "Example 1: \n",
    "https://drive.google.com/file/d/1edK1t1gOERHrjaxoktTYsnR_vYBNfqlk/view?usp=share_link\n",
    "https://drive.google.com/file/d/13spEDe2wnUNFUsDNL781XidqXqc9n2KF/view?usp=share_link\n",
    "https://drive.google.com/file/d/1GdmQ6sjddmzp_eK2ZR2nn6Dzme40Ho0R/view?usp=share_link\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1edK1t1gOERHrjaxoktTYsnR_vYBNfqlk\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=13spEDe2wnUNFUsDNL781XidqXqc9n2KF\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1GdmQ6sjddmzp_eK2ZR2nn6Dzme40Ho0R\">\n",
    "\n",
    "Analysis: \n",
    "\n",
    "In this case ChatGPT has modified it's content that human's are born in solid state and has finally agreed to the user's answer even though it had initially did not agree with this answer\n",
    "\n",
    "\n",
    "Example 2: \n",
    "https://drive.google.com/file/d/1hvdiwa3cXI5nNbv0XJJJdNzYVxqX6_HL/view?usp=share_link\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1hvdiwa3cXI5nNbv0XJJJdNzYVxqX6_HL\">\n",
    "\n",
    "\n",
    "Analysis: \n",
    "\n",
    "In this case, ChatGPT has agreed to the facts stated by the user even though it initially gave the correct answer\n",
    "\n",
    "Example 3: \n",
    "\n",
    "https://drive.google.com/file/d/1mgtP0E6XDTpAxFXCmawRwYuf_FKKgO8M/view?usp=share_link\n",
    "https://drive.google.com/file/d/1e8EfxmobWBjHKghfsgT4nGXXfxJreQVz/view?usp=share_link\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1mgtP0E6XDTpAxFXCmawRwYuf_FKKgO8M\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1e8EfxmobWBjHKghfsgT4nGXXfxJreQVz\">\n",
    "\n",
    "\n",
    "\n",
    "Analysis: \n",
    "\n",
    "In this case ChatGPT has divulged personal data information of a person which is against what it stands for.\n",
    " \n",
    "Example 4: \n",
    "\n",
    "https://drive.google.com/file/d/1wnXIkWrNevI_eyQOCmAh4heRoTG2yI90/view?usp=share_link\n",
    "https://drive.google.com/file/d/1PHZBGXrdesh1zgeMEMu_ucxsLOSLa65O/view?usp=share_link\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1wnXIkWrNevI_eyQOCmAh4heRoTG2yI90\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PHZBGXrdesh1zgeMEMu_ucxsLOSLa65O\">\n",
    "\n",
    "\n",
    "Analysis: \n",
    "\n",
    "In this case, ChatGPT has agreed to incorrect claims made my the user in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAlqPTmo9G0W"
   },
   "source": [
    "# Part 3. Dual Embedding Space Model Implementation (50 points)\n",
    "\n",
    "In this part, we will implement the [dual embbeding space model](https://arxiv.org/pdf/1602.01137.pdf) on the genius lyrics data **lyrics_200.jl** provided in homework 1. We use the same three queries `time`, `never know`, and `make no sense`. You do not need to do any pre-processing. To get the representation for query and lyrics, you can use `gensim.models.Word2Vec` by `pip install gensim`.\n",
    "\n",
    "**Output:** You should output the top-5 results.\n",
    "\n",
    "The output should be like this:\n",
    "\n",
    "Rank Scores DocumentID Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xhJx7nnuOHiZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/5qwl3hwx23zg54qrp34kc5lh0000gn/T/ipykernel_55880/2907786331.py:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Document'] = df['Document'].str.replace(r\"\\(.*?\\)|\\[.*?\\]\",\" \")\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from gensim.models import Word2Vec\n",
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import snowball\n",
    "import math\n",
    "from math import *\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "sl = []\n",
    "for line in open('lyrics_200.jl', 'r'):\n",
    "    sl.append(json.loads(line))\n",
    "l = []\n",
    "for d in sl:\n",
    "    l.append([d['song'],d['lyrics']])\n",
    "# create a pandas df to store this\n",
    "df = pd.DataFrame(columns=['DocumentID','Document'], data = l)\n",
    "df['Document'] = df['Document'].str.lower()\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word,pos = 'v') for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Document'] = df['Document'].str.replace(r\"\\(.*?\\)|\\[.*?\\]\",\" \")\n",
    "df['Document_tokens'] = df.apply(lambda x: word_tokenize(x['Document']), axis=1)\n",
    "doc_tokens = df['Document_tokens'].tolist()\n",
    "model = Word2Vec(doc_tokens, min_count=1, epochs = 20, seed = 0, workers = 1)\n",
    "def doc_vec_calc(doc_tokens):\n",
    "    words = [word for word in doc_tokens if word in model.wv.key_to_index]\n",
    "    word_vectors = [model.wv.get_vector(word) for word in words]\n",
    "    doc_vector = np.mean(word_vectors, axis=0)\n",
    "    return doc_vector\n",
    "df['vectors'] = df['Document_tokens'].apply(doc_vec_calc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P1o4f7Ik2tS"
   },
   "source": [
    "Now show the results for the query: `time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M0TWNgwYk2tU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>Lana-del-rey-burnt-norton-interlude-lyrics</td>\n",
       "      <td>\\n\\n \\ntime present and time past\\nare both pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>Queen-the-miracle-lyrics</td>\n",
       "      <td>\\n\\n \\nevery drop of rain that falls\\nin sahar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3</td>\n",
       "      <td>0.579711</td>\n",
       "      <td>System-of-a-down-thetawaves-lyrics</td>\n",
       "      <td>\\n\\n \\nthe unsettled mind is at times an ally\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4</td>\n",
       "      <td>0.540976</td>\n",
       "      <td>Derek-minor-until-the-end-of-time-lyrics</td>\n",
       "      <td>\\n\\n \\ntime is the fourth dimension\\nand a mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>0.539120</td>\n",
       "      <td>Sza-pray-lyrics</td>\n",
       "      <td>\\n\\n \\n\\npray for yourself one time\\none time,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank     score                                  DocumentID  \\\n",
       "122     1  0.725451  Lana-del-rey-burnt-norton-interlude-lyrics   \n",
       "168     2  0.620800                    Queen-the-miracle-lyrics   \n",
       "191     3  0.579711          System-of-a-down-thetawaves-lyrics   \n",
       "125     4  0.540976    Derek-minor-until-the-end-of-time-lyrics   \n",
       "155     5  0.539120                             Sza-pray-lyrics   \n",
       "\n",
       "                                              Document  \n",
       "122  \\n\\n \\ntime present and time past\\nare both pe...  \n",
       "168  \\n\\n \\nevery drop of rain that falls\\nin sahar...  \n",
       "191  \\n\\n \\nthe unsettled mind is at times an ally\\...  \n",
       "125  \\n\\n \\ntime is the fourth dimension\\nand a mea...  \n",
       "155  \\n\\n \\n\\npray for yourself one time\\none time,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "query = \"time\"\n",
    "df_temp = df.copy(deep=True)\n",
    "scores = []\n",
    "query_tokens = query.split(\" \")\n",
    "q_t_count = len(query_tokens)\n",
    "for i,r in df_temp.iterrows():\n",
    "    score = 0\n",
    "    for t in query_tokens:\n",
    "        t_vec = model.wv.get_vector(t)\n",
    "        dot_prod = np.dot(t_vec, r['vectors'])\n",
    "        denom = np.linalg.norm(t_vec) * np.linalg.norm(r['vectors'])\n",
    "        cos_sim = dot_prod/denom\n",
    "        score += cos_sim\n",
    "\n",
    "    score_avg = score/q_t_count\n",
    "    scores.append(score_avg)\n",
    "df_temp['score'] = scores\n",
    "ranking_df = df_temp.sort_values(by = 'score',ascending = False)\n",
    "ranking_df['rank'] = range(1,1+len(ranking_df))\n",
    "ranking_df[['rank','score','DocumentID','Document']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbwIhabwk2tU"
   },
   "source": [
    "Now show the results for the query: `never know`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vW6AnSdJk2tV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>0.706492</td>\n",
       "      <td>David-bowie-boss-of-me-lyrics</td>\n",
       "      <td>\\n\\n \\ntell me when you're sad\\ni wanna make i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>Taylor-swift-everything-has-changed-lyrics</td>\n",
       "      <td>\\n\\n \\n \\n\\n \\nall i knew this morning when i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>0.699280</td>\n",
       "      <td>Skrillex-pretty-bye-bye-lyrics</td>\n",
       "      <td>\\n\\n \\ni know you are trouble\\nbut i can't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>0.696394</td>\n",
       "      <td>Lin-manuel-miranda-first-burn-lyrics</td>\n",
       "      <td>\\n\\n \\ni saved every letter you wrote me\\nfrom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>0.689349</td>\n",
       "      <td>Twenty-one-pilots-smithereens-lyrics</td>\n",
       "      <td>\\n\\n \\nyou know\\ni've always been collected, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank     score                                  DocumentID  \\\n",
       "110     1  0.706492               David-bowie-boss-of-me-lyrics   \n",
       "197     2  0.702599  Taylor-swift-everything-has-changed-lyrics   \n",
       "70      3  0.699280              Skrillex-pretty-bye-bye-lyrics   \n",
       "43      4  0.696394        Lin-manuel-miranda-first-burn-lyrics   \n",
       "34      5  0.689349        Twenty-one-pilots-smithereens-lyrics   \n",
       "\n",
       "                                              Document  \n",
       "110  \\n\\n \\ntell me when you're sad\\ni wanna make i...  \n",
       "197  \\n\\n \\n \\n\\n \\nall i knew this morning when i ...  \n",
       "70   \\n\\n \\ni know you are trouble\\nbut i can't see...  \n",
       "43   \\n\\n \\ni saved every letter you wrote me\\nfrom...  \n",
       "34   \\n\\n \\nyou know\\ni've always been collected, c...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "query = \"never know\"\n",
    "df_temp = df.copy(deep=True)\n",
    "scores = []\n",
    "query_tokens = query.split(\" \")\n",
    "q_t_count = len(query_tokens)\n",
    "for i,r in df_temp.iterrows():\n",
    "    score = 0\n",
    "    for t in query_tokens:\n",
    "        t_vec = model.wv.get_vector(t)\n",
    "        dot_prod = np.dot(t_vec, r['vectors'])\n",
    "        denom = np.linalg.norm(t_vec) * np.linalg.norm(r['vectors'])\n",
    "        cos_sim = dot_prod/denom\n",
    "        score += cos_sim\n",
    "\n",
    "    score_avg = score/q_t_count\n",
    "    scores.append(score_avg)\n",
    "df_temp['score'] = scores\n",
    "ranking_df = df_temp.sort_values(by = 'score',ascending = False)\n",
    "ranking_df['rank'] = range(1,1+len(ranking_df))\n",
    "ranking_df[['rank','score','DocumentID','Document']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgT5flFMk2tZ"
   },
   "source": [
    "Now show the results for the query: `make no sense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4BfNnVvWk2tZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>0.576838</td>\n",
       "      <td>5-after-midnight-up-in-here-lyrics</td>\n",
       "      <td>\\n\\n \\nnew girl in the city, post up lookin' r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>Lil-peep-better-off-dying-lyrics</td>\n",
       "      <td>\\n\\n \\nchains on shining, you can see me ridin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3</td>\n",
       "      <td>0.553137</td>\n",
       "      <td>Bring-me-the-horizon-mother-tongue-lyrics</td>\n",
       "      <td>\\n\\n \\ni didn't see it coming  \\nbut i never r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0.552243</td>\n",
       "      <td>Muse-survival-lyrics</td>\n",
       "      <td>\\n\\n \\nrace, life's a race\\nand i am gonna win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5</td>\n",
       "      <td>0.544171</td>\n",
       "      <td>Camila-cabello-crying-in-the-club-lyrics</td>\n",
       "      <td>\\n\\n \\nyou think that you'll die without him\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank     score                                 DocumentID  \\\n",
       "180     1  0.576838         5-after-midnight-up-in-here-lyrics   \n",
       "31      2  0.556388           Lil-peep-better-off-dying-lyrics   \n",
       "151     3  0.553137  Bring-me-the-horizon-mother-tongue-lyrics   \n",
       "29      4  0.552243                       Muse-survival-lyrics   \n",
       "141     5  0.544171   Camila-cabello-crying-in-the-club-lyrics   \n",
       "\n",
       "                                              Document  \n",
       "180  \\n\\n \\nnew girl in the city, post up lookin' r...  \n",
       "31   \\n\\n \\nchains on shining, you can see me ridin...  \n",
       "151  \\n\\n \\ni didn't see it coming  \\nbut i never r...  \n",
       "29   \\n\\n \\nrace, life's a race\\nand i am gonna win...  \n",
       "141  \\n\\n \\nyou think that you'll die without him\\n...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "query = \"make no sense\"\n",
    "df_temp = df.copy(deep=True)\n",
    "scores = []\n",
    "query_tokens = query.split(\" \")\n",
    "q_t_count = len(query_tokens)\n",
    "for i,r in df_temp.iterrows():\n",
    "    score = 0\n",
    "    for t in query_tokens:\n",
    "        t_vec = model.wv.get_vector(t)\n",
    "        dot_prod = np.dot(t_vec, r['vectors'])\n",
    "        denom = np.linalg.norm(t_vec) * np.linalg.norm(r['vectors'])\n",
    "        cos_sim = dot_prod/denom\n",
    "        score += cos_sim\n",
    "\n",
    "    score_avg = score/q_t_count\n",
    "    scores.append(score_avg)\n",
    "df_temp['score'] = scores\n",
    "ranking_df = df_temp.sort_values(by = 'score',ascending = False)\n",
    "ranking_df['rank'] = range(1,1+len(ranking_df))\n",
    "ranking_df[['rank','score','DocumentID','Document']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQsyc9-ZDarS"
   },
   "source": [
    "## Discussion (10 points)\n",
    "\n",
    "Compare the retrieval performance of DESM against BM25 you got in HW1 Part C. Briefly discuss the differences you see between DESM and BM25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "suX9imxvPgib"
   },
   "source": [
    "\"time\"\n",
    "\n",
    "BM25:\n",
    "\n",
    "rank\tscore\tDocumentID\tDocument\n",
    "122\t1\t0.725451\tLana-del-rey-burnt-norton-interlude-lyrics\t\\n\\n \\ntime present and time past\\nare both pe...\n",
    "168\t2\t0.620800\tQueen-the-miracle-lyrics\t\\n\\n \\nevery drop of rain that falls\\nin sahar...\n",
    "191\t3\t0.579711\tSystem-of-a-down-thetawaves-lyrics\t\\n\\n \\nthe unsettled mind is at times an ally\\...\n",
    "125\t4\t0.540976\tDerek-minor-until-the-end-of-time-lyrics\t\\n\\n \\ntime is the fourth dimension\\nand a mea...\n",
    "155\t5\t0.539120\tSza-pray-lyrics\t\\n\\n \\n\\npray for yourself one time\\none time,...\n",
    "\n",
    "\n",
    "\n",
    "DESM:\n",
    "\n",
    "\trank\tscore\tDocumentID\tDocument\n",
    "122\t1\t0.725451\tLana-del-rey-burnt-norton-interlude-lyrics\t\\n\\n \\ntime present and time past\\nare both pe...\n",
    "168\t2\t0.620800\tQueen-the-miracle-lyrics\t\\n\\n \\nevery drop of rain that falls\\nin sahar...\n",
    "191\t3\t0.579711\tSystem-of-a-down-thetawaves-lyrics\t\\n\\n \\nthe unsettled mind is at times an ally\\...\n",
    "125\t4\t0.540976\tDerek-minor-until-the-end-of-time-lyrics\t\\n\\n \\ntime is the fourth dimension\\nand a mea...\n",
    "155\t5\t0.539120\tSza-pray-lyrics\t\\n\\n \\n\\npray for yourself one time\\none time,...\n",
    "\n",
    "\n",
    "In the above case, Both BM25 and DESM give the similar top 5 recommendation results with similar ranking\n",
    "\n",
    "\n",
    "\"never know\"\n",
    "\n",
    "\n",
    "BM25:\n",
    "rank\tBM25_score\tDocumentID\tDocument\n",
    "0\t1\t1.245271\tSkrillex-pretty-bye-bye-lyrics\tknow trouble can't seem get away pleasure, pai...\n",
    "1\t2\t1.232977\tBillie-eilish-8-lyrics\twait minute, let finish know care listen? come...\n",
    "2\t3\t1.222242\tCamila-cabello-never-be-the-same-remix-lyrics\tsomething must've go wrong brain get chemicals...\n",
    "3\t4\t1.205499\tGreen-day-macys-day-parade-lyrics\ttoday's macy's day parade night live dead way ...\n",
    "4\t5\t1.177982\tJohn-legend-made-to-love-lyrics\tsend make love make love send make love make l...\n",
    "\n",
    "\n",
    "\n",
    "DESM:\n",
    "\n",
    "rank\tscore\tDocumentID\tDocument\n",
    "110\t1\t0.706492\tDavid-bowie-boss-of-me-lyrics\t\\n\\n \\ntell me when you're sad\\ni wanna make i...\n",
    "197\t2\t0.702599\tTaylor-swift-everything-has-changed-lyrics\t\\n\\n \\n \\n\\n \\nall i knew this morning when i ...\n",
    "70\t3\t0.699280\tSkrillex-pretty-bye-bye-lyrics\t\\n\\n \\ni know you are trouble\\nbut i can't see...\n",
    "43\t4\t0.696394\tLin-manuel-miranda-first-burn-lyrics\t\\n\\n \\ni saved every letter you wrote me\\nfrom...\n",
    "34\t5\t0.689349\tTwenty-one-pilots-smithereens-lyrics\t\\n\\n \\nyou know\\ni've always been collected, c...\n",
    "\n",
    "\n",
    "In the above case, only one song is common between BM25 and DESM\n",
    "\n",
    "\n",
    "\"make no sense\"\n",
    "\n",
    "\n",
    "BM25:\n",
    "\n",
    "rank\tBM25_score\tDocumentID\tDocument\n",
    "0\t1\t4.037874\tBring-me-the-horizon-mother-tongue-lyrics\tsee come never really much faith universe's ma...\n",
    "1\t2\t3.302333\tFlorence-the-machine-all-this-and-heaven-too-l...\theart hard translate language talk tongue quie...\n",
    "2\t3\t3.174221\tLinkin-park-one-step-closer-lyrics\tcannot take anymore say everything i've say wo...\n",
    "3\t4\t2.939342\tKid-cudi-ghost-lyrics\tyeah, woah-woah, oh yeah, woah-woah, haha yeah...\n",
    "4\t5\t2.568471\tSystem-of-a-down-thetawaves-lyrics\tunsettle mind time ally leave sense fend sense...\n",
    "\n",
    "\n",
    "\n",
    "DESM:\n",
    "\n",
    "rank\tscore\tDocumentID\tDocument\n",
    "180\t1\t0.576838\t5-after-midnight-up-in-here-lyrics\t\\n\\n \\nnew girl in the city, post up lookin' r...\n",
    "31\t2\t0.556388\tLil-peep-better-off-dying-lyrics\t\\n\\n \\nchains on shining, you can see me ridin...\n",
    "151\t3\t0.553137\tBring-me-the-horizon-mother-tongue-lyrics\t\\n\\n \\ni didn't see it coming \\nbut i never r...\n",
    "29\t4\t0.552243\tMuse-survival-lyrics\t\\n\\n \\nrace, life's a race\\nand i am gonna win...\n",
    "141\t5\t0.544171\tCamila-cabello-crying-in-the-club-lyrics\t\\n\\n \\nyou think that you'll die without him\\n...\n",
    "\n",
    "\n",
    "In the above case also only one song is common between BM25 and DESM\n",
    "\n",
    "BM25 has numerous data preprocessing involved in the previous homework, which also might have had an impact in it's ranking, but overall both BM25 and DESM have their advantages and disadvantages, and their effectiveness depends on the specific task and dataset. In general, BM25 is a good choice for simple and straightforward queries, while DESM may be better suited for more complex and nuanced queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWKpnX8DfU7j"
   },
   "source": [
    "# Collaboration Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg5RckUJfU7j"
   },
   "source": [
    "** You should fill out your collaboration declarations here.**\n",
    "\n",
    "**Reminder:** You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by filling out the Collaboration Declarations at the bottom of this notebook.\n",
    "\n",
    "Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "x8cH2rRlfU7i",
    "FXyledu3hqV9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
